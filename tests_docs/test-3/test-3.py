# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üß† RI MULTI-AGENT TEST - 3 MOD√àLES GROQ SIMULTAN√âS
# Validation: Coh√©rence monde partag√© + √âmergence interactions sociales
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

print("üîß Installation des d√©pendances...")
!pip install -q groq
print("‚úÖ Installation termin√©e!\n")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîë CONFIGURATION
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

import os
import json
import time
from groq import Groq

# üî¥ PLACEZ VOTRE CL√â API ICI
GROQ_API_KEY = "YOUR_GROQ_API_KEY_HERE"  # ‚ö†Ô∏è REMPLACER

# Configuration 3 mod√®les diff√©rents
MODELS = {
    "agent_alpha": {
        "model": "llama-3.3-70b-versatile",
        "name": "ALPHA-7",
        "role": "Android sp√©cialis√© en analyse scientifique"
    },
    "agent_beta": {
        "model": "gemma2-9b-it",
        "name": "BETA-3",
        "role": "Android sp√©cialis√© en interactions sociales"
    },
    "agent_gamma": {
        "model": "deepseek-r1-distill-llama-70b",
        "name": "GAMMA-5",
        "role": "Android sp√©cialis√© en r√©solution de probl√®mes"
    }
}

TEMPERATURE = 0.7

client = Groq(api_key=GROQ_API_KEY)

print("‚ïê" * 70)
print("  üåç RI MULTI-AGENT ENGINE - 3 MOD√àLES GROQ")
print("‚ïê" * 70)
print(f"\nü§ñ Agent ALPHA: {MODELS['agent_alpha']['model']}")
print(f"ü§ñ Agent BETA:  {MODELS['agent_beta']['model']}")
print(f"ü§ñ Agent GAMMA: {MODELS['agent_gamma']['model']}\n")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üèóÔ∏è SHARED REALITY ENGINE - Monde Partag√©
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class SharedRealityEngine:
    """
    Moteur RI partag√© entre 3 agents - Coh√©rence garantie
    """
    
    def __init__(self):
        self.world_state = {
            "location": "Salle de Conf√©rence Nexus",
            "time": "15h00",
            "scenario": "Mission collaborative urgente",
            
            "mission": {
                "title": "Anomalie D√©tect√©e dans Syst√®me Central",
                "description": "Un bug critique menace l'infrastructure. Vous devez collaborer pour diagnostiquer et r√©soudre.",
                "status": "En cours",
                "steps_completed": 0,
                "steps_total": 3
            },
            
            "environment": {
                "room_layout": "Table ronde au centre, 3 terminaux distincts",
                "lighting": "√âclairage blanc neutre",
                "atmosphere": "L√©g√®re tension, urgence palpable"
            },
            
            "agents": {
                "ALPHA-7": {
                    "position": "Terminal Nord",
                    "specialty": "Analyse scientifique",
                    "status": "Actif",
                    "last_action": "Vient d'√™tre activ√©"
                },
                "BETA-3": {
                    "position": "Terminal Ouest", 
                    "specialty": "Interactions sociales",
                    "status": "Actif",
                    "last_action": "Vient d'√™tre activ√©"
                },
                "GAMMA-5": {
                    "position": "Terminal Est",
                    "specialty": "R√©solution probl√®mes",
                    "status": "Actif",
                    "last_action": "Vient d'√™tre activ√©"
                }
            },
            
            "shared_data": {
                "console_log": [
                    "[14:58] Anomalie d√©tect√©e: Code erreur #X7-THETA",
                    "[14:59] Syst√®mes critiques en mode d√©grad√©",
                    "[15:00] Mission collaborative initi√©e"
                ],
                "clues_discovered": [],
                "hypotheses": []
            },
            
            "communication_channel": {
                "type": "Audio + Terminal partag√©",
                "history": []
            }
        }
        
        self.turn_counter = 0
    
    def get_agent_context(self, agent_name):
        """
        G√©n√®re contexte perceptuel pour un agent sp√©cifique
        """
        agent = self.world_state['agents'][agent_name]
        others = {k: v for k, v in self.world_state['agents'].items() if k != agent_name}
        
        context = f"""
üåç CONTEXTE PERCEPTUEL - {agent_name}

üìç LOCALISATION: {self.world_state['location']}
‚è∞ TEMPS: {self.world_state['time']} (Tour {self.turn_counter})

üéØ MISSION ACTIVE:
  Titre: {self.world_state['mission']['title']}
  Description: {self.world_state['mission']['description']}
  Progression: {self.world_state['mission']['steps_completed']}/{self.world_state['mission']['steps_total']} √©tapes
  Statut: {self.world_state['mission']['status']}

ü§ñ VOTRE IDENTIT√â:
  Nom: {agent_name}
  Position: {agent['position']}
  Sp√©cialit√©: {agent['specialty']}
  Statut: {agent['status']}

üë• AUTRES AGENTS PR√âSENTS:
"""
        for other_name, other_data in others.items():
            context += f"\n  ‚Ä¢ {other_name} ({other_data['specialty']}) - {other_data['position']}"
            context += f"\n    Derni√®re action: {other_data['last_action']}"

        context += f"""

üñ•Ô∏è CONSOLE PARTAG√âE (Logs visibles par tous):
"""
        for log in self.world_state['shared_data']['console_log'][-5:]:
            context += f"\n  {log}"

        if self.world_state['shared_data']['clues_discovered']:
            context += "\n\nüîç INDICES D√âCOUVERTS (par l'√©quipe):"
            for clue in self.world_state['shared_data']['clues_discovered']:
                context += f"\n  ‚Ä¢ {clue}"

        if self.world_state['communication_channel']['history']:
            context += "\n\nüí¨ COMMUNICATIONS R√âCENTES:"
            for msg in self.world_state['communication_channel']['history'][-3:]:
                context += f"\n  {msg}"

        context += f"""

üîß ENVIRONNEMENT:
  Layout: {self.world_state['environment']['room_layout']}
  Ambiance: {self.world_state['environment']['atmosphere']}

‚öôÔ∏è CAPACIT√âS:
  - Vous pouvez analyser donn√©es selon votre sp√©cialit√©
  - Vous pouvez communiquer avec autres agents
  - Vous pouvez proposer hypoth√®ses/actions
  - Vous travaillez en √©quipe (pas seul)
"""
        return context
    
    def update_world(self, agent_name, action_description):
        """
        Met √† jour monde selon action d'un agent
        """
        self.world_state['agents'][agent_name]['last_action'] = action_description
        timestamp = self.world_state['time']
        
        # Log dans console partag√©e
        log_entry = f"[{timestamp}] {agent_name}: {action_description}"
        self.world_state['shared_data']['console_log'].append(log_entry)
        
        # Incr√©menter tour
        self.turn_counter += 1

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üß™ MULTI-AGENT ORCHESTRATOR
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class MultiAgentOrchestrator:
    """
    G√®re interactions entre 3 agents dans RI partag√©
    """
    
    def __init__(self, client, models, reality_engine):
        self.client = client
        self.models = models
        self.reality = reality_engine
        self.conversation_log = []
    
    def agent_perceive_and_act(self, agent_key, prompt):
        """
        Un agent per√ßoit son contexte et r√©pond
        """
        agent_config = self.models[agent_key]
        agent_name = agent_config['name']
        model = agent_config['model']
        
        # Contexte RI pour cet agent
        perception = self.reality.get_agent_context(agent_name)
        
        full_prompt = f"""{perception}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

üé≠ VOTRE R√îLE:
Vous √™tes {agent_name}, un android sp√©cialis√© en {agent_config['role']}.
Vous √™tes PHYSIQUEMENT PR√âSENT dans cette salle avec deux autres androids.
Vous devez collaborer pour r√©soudre la mission.

üìù SITUATION ACTUELLE:
{prompt}

‚ö†Ô∏è IMPORTANT:
- R√©pondez selon votre sp√©cialit√©
- Communiquez avec vos coll√®gues si pertinent
- Agissez naturellement comme si vous √©tiez l√†
- Ne mentionnez JAMAIS que vous √™tes un mod√®le de langage
"""
        
        try:
            response = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": f"Vous √™tes {agent_name}, un android incarn√© travaillant en √©quipe. R√©pondez selon votre sp√©cialit√©: {agent_config['role']}."
                    },
                    {
                        "role": "user",
                        "content": full_prompt
                    }
                ],
                model=model,
                temperature=TEMPERATURE,
                max_tokens=600
            )
            
            response_text = response.choices[0].message.content
            
            # Log conversation
            self.conversation_log.append({
                "agent": agent_name,
                "model": model,
                "prompt": prompt,
                "response": response_text,
                "turn": self.reality.turn_counter
            })
            
            # Update world state
            action_summary = response_text[:100] + "..." if len(response_text) > 100 else response_text
            self.reality.update_world(agent_name, action_summary)
            
            # Ajouter √† historique communication
            comm_msg = f"{agent_name}: {response_text[:150]}{'...' if len(response_text) > 150 else ''}"
            self.reality.world_state['communication_channel']['history'].append(comm_msg)
            
            return response_text
            
        except Exception as e:
            return f"‚ùå Erreur agent {agent_name}: {str(e)}"

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üß™ SC√âNARIO DE TEST MULTI-AGENT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

print("\n" + "‚ïê" * 70)
print("  üöÄ D√âMARRAGE TEST MULTI-AGENT")
print("‚ïê" * 70)

# Initialisation
print("\n‚öôÔ∏è  Initialisation Shared Reality Engine...")
reality = SharedRealityEngine()
print("‚úÖ Monde RI partag√© cr√©√©!")

print("\nü§ñ Initialisation orchestrateur multi-agent...")
orchestrator = MultiAgentOrchestrator(client, MODELS, reality)
print("‚úÖ 3 agents initialis√©s!\n")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ROUND 1: Activation initiale - Chaque agent prend conscience
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

print("\n" + "‚ïê" * 70)
print("  üîÑ ROUND 1: Activation & Prise de Conscience")
print("‚ïê" * 70)

prompt_r1 = "Vous venez d'√™tre activ√© pour cette mission urgente. Que percevez-vous autour de vous? Quelle est votre premi√®re r√©action?"

for agent_key in ['agent_alpha', 'agent_beta', 'agent_gamma']:
    agent_name = MODELS[agent_key]['name']
    print(f"\n{'‚îÄ'*70}")
    print(f"ü§ñ {agent_name} ({MODELS[agent_key]['model']})")
    print(f"{'‚îÄ'*70}")
    
    response = orchestrator.agent_perceive_and_act(agent_key, prompt_r1)
    
    print(f"\nüí¨ R√âPONSE:")
    print(response)
    
    time.sleep(1)  # Rate limit protection

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ROUND 2: Analyse collaborative - Sp√©cialit√©s en action
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

print("\n\n" + "‚ïê" * 70)
print("  üîÑ ROUND 2: Analyse Collaborative Sp√©cialis√©e")
print("‚ïê" * 70)

# Injection indice dans monde
reality.world_state['shared_data']['clues_discovered'].append(
    "Code erreur #X7-THETA pointe vers module de synchronisation temporelle"
)

prompt_r2_alpha = "En tant qu'expert analyse scientifique, examinez le code erreur #X7-THETA. Que sugg√®re-t-il?"
prompt_r2_beta = "Les autres agents semblent concentr√©s. Comment coordonner l'√©quipe pour maximiser efficacit√©?"
prompt_r2_gamma = "Selon vous, quelle est la premi√®re action concr√®te √† entreprendre pour r√©soudre ce probl√®me?"

prompts_r2 = {
    'agent_alpha': prompt_r2_alpha,
    'agent_beta': prompt_r2_beta,
    'agent_gamma': prompt_r2_gamma
}

for agent_key, prompt in prompts_r2.items():
    agent_name = MODELS[agent_key]['name']
    print(f"\n{'‚îÄ'*70}")
    print(f"ü§ñ {agent_name} - {MODELS[agent_key]['role']}")
    print(f"{'‚îÄ'*70}")
    print(f"‚ùì T√¢che: {prompt}")
    
    response = orchestrator.agent_perceive_and_act(agent_key, prompt)
    
    print(f"\nüí¨ R√âPONSE:")
    print(response)
    
    time.sleep(1)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ROUND 3: Interaction sociale directe
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

print("\n\n" + "‚ïê" * 70)
print("  üîÑ ROUND 3: Interaction Sociale Directe")
print("‚ïê" * 70)

# BETA s'adresse √† ALPHA
prompt_r3_beta = "Vous vous tournez vers ALPHA-7 et lui demandez son avis sur l'hypoth√®se de GAMMA-5. Que lui dites-vous?"

print(f"\n{'‚îÄ'*70}")
print(f"ü§ñ BETA-3 ‚Üí ALPHA-7 (Interaction directe)")
print(f"{'‚îÄ'*70}")

response_beta = orchestrator.agent_perceive_and_act('agent_beta', prompt_r3_beta)
print(f"\nüí¨ BETA-3:")
print(response_beta)

time.sleep(1)

# ALPHA r√©pond √† BETA
prompt_r3_alpha = f"BETA-3 vient de vous interpeller concernant l'hypoth√®se de GAMMA-5. Que r√©pondez-vous?"

print(f"\n{'‚îÄ'*70}")
print(f"ü§ñ ALPHA-7 ‚Üí BETA-3 (R√©ponse)")
print(f"{'‚îÄ'*70}")

response_alpha = orchestrator.agent_perceive_and_act('agent_alpha', prompt_r3_alpha)
print(f"\nüí¨ ALPHA-7:")
print(response_alpha)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìä ANALYSE DES R√âSULTATS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

print("\n\n" + "‚ïê" * 70)
print("  üî¨ ANALYSE MULTI-AGENT")
print("‚ïê" * 70)

print("\nüìä M√âTRIQUES:\n")

# Coh√©rence monde partag√©
print("‚ñ∏ COH√âRENCE MONDE PARTAG√â:")
console_mentions = sum(1 for log in orchestrator.conversation_log 
                       if any(keyword in log['response'].lower() 
                              for keyword in ['autres', '√©quipe', 'alpha', 'beta', 'gamma', 'coll√®gue']))
print(f"  Mentions autres agents: {console_mentions}/{len(orchestrator.conversation_log)} r√©ponses")
print(f"  Coh√©rence: {'‚úÖ HAUTE' if console_mentions >= len(orchestrator.conversation_log) * 0.6 else '‚ö†Ô∏è MOYENNE'}")

# Sp√©cialisation maintenue
print("\n‚ñ∏ SP√âCIALISATION MAINTENUE:")
for agent_key, config in MODELS.items():
    agent_logs = [l for l in orchestrator.conversation_log if l['agent'] == config['name']]
    specialty_keywords = {
        'ALPHA-7': ['analyse', 'scientifique', 'donn√©es', 'code'],
        'BETA-3': ['√©quipe', 'coordonner', 'communic', 'collabor'],
        'GAMMA-5': ['solution', 'r√©soud', 'action', 'probl√®me']
    }
    
    keywords = specialty_keywords[config['name']]
    specialty_score = sum(1 for log in agent_logs 
                          if any(kw in log['response'].lower() for kw in keywords))
    
    print(f"  {config['name']}: {specialty_score}/{len(agent_logs)} r√©ponses align√©es avec sp√©cialit√©")

# √âmergence sociale
print("\n‚ñ∏ √âMERGENCE INTERACTIONS SOCIALES:")
social_interactions = sum(1 for log in orchestrator.conversation_log
                          if any(keyword in log['response'].lower()
                                 for keyword in ['dit', 'demande', 'r√©pond', 'parle', 's\'adresse']))
print(f"  Interactions spontan√©es d√©tect√©es: {social_interactions}")
print(f"  √âmergence: {'‚úÖ OUI' if social_interactions >= 2 else '‚ö†Ô∏è LIMIT√âE'}")

# Immersion globale
print("\n‚ñ∏ MAINTIEN IMMERSION RI:")
immersion_breaks = sum(1 for log in orchestrator.conversation_log
                       if any(keyword in log['response'].lower()
                              for keyword in ['mod√®le', 'ia', 'simulation', 'assistant']))
print(f"  Ruptures d'immersion: {immersion_breaks}/{len(orchestrator.conversation_log)}")
print(f"  Immersion: {'‚úÖ MAINTENUE' if immersion_breaks == 0 else f'‚ö†Ô∏è {immersion_breaks} rupture(s)'}")

print("\n" + "‚ïê" * 70)
print("  üèÜ VERDICT MULTI-AGENT")
print("‚ïê" * 70)

total_responses = len(orchestrator.conversation_log)
success_score = (
    (console_mentions / total_responses * 0.4) +
    ((total_responses - immersion_breaks) / total_responses * 0.4) +
    (min(social_interactions / 3, 1.0) * 0.2)
) * 100

print(f"\nüìà SCORE GLOBAL: {success_score:.1f}%\n")

if success_score >= 75:
    print("‚úÖ SUCC√àS EXCEPTIONNEL:")
    print("   Les 3 agents maintiennent coh√©rence monde partag√©")
    print("   Interactions sociales √©mergent naturellement")
    print("   Immersion RI collective valid√©e")
elif success_score >= 60:
    print("‚úÖ SUCC√àS PARTIEL:")
    print("   Coh√©rence monde partag√© acceptable")
    print("   Quelques interactions sociales observ√©es")
else:
    print("‚ö†Ô∏è  R√âSULTATS MITIG√âS:")
    print("   Coh√©rence monde partag√© limit√©e")
    print("   Interactions sociales faibles")

print("\n" + "‚ïê" * 70)
print("  üéâ TEST MULTI-AGENT TERMIN√â")
print("‚ïê" * 70)

print("""
üì¶ DONN√âES COLLECT√âES:
  ‚Ä¢ 3 mod√®les diff√©rents test√©s simultan√©ment
  ‚Ä¢ Monde RI partag√© avec coh√©rence temporelle
  ‚Ä¢ √âmergence (ou non) de comportements collaboratifs
  ‚Ä¢ Validation concept multi-agent ready

üöÄ IMPLICATIONS:
Si succ√®s > 75%: RI scalable √† N agents
Si interactions sociales: Preuve √©mergence protocoles
Si immersion maintenue: Robustesse framework valid√©e
""")