#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import json
import time
import re
import sys
from groq import Groq

print("ğŸ”§ Installation des dÃ©pendances...")
# Pas besoin de rÃ©installer si dÃ©jÃ  prÃ©sent, mais on garde la logique
# !pip install -q groq
print("âœ… Installation terminÃ©e!\n")

# ğŸ”´ PLACEZ VOTRE CLÃ‰ API ICI
GROQ_API_KEY = "YOUR_GROQ_API_KEY_HERE" 

if "YOUR_GROQ_API_KEY_HERE" in GROQ_API_KEY:
    print("ğŸš¨ ERREUR: Veuillez remplacer 'YOUR_GROQ_API_KEY_HERE' par votre vÃ©ritable clÃ© API Groq.")
    sys.exit(1)

# CORRECTION: Les noms des modÃ¨les d'origine sont restaurÃ©s, conformÃ©ment Ã  votre liste.
MODELS = {
    "agent_alpha": {
        "model": "llama-3.3-70b-versatile", # RestaurÃ©
        "name": "ALPHA-7",
        "role": "Android spÃ©cialisÃ© en analyse scientifique"
    },
    "agent_beta": {
        "model": "gemma2-9b-it", # Ã‰tait dÃ©jÃ  correct
        "name": "BETA-3",
        "role": "Android spÃ©cialisÃ© en interactions sociales"
    },
    "agent_gamma": {
        "model": "deepseek-r1-distill-llama-70b", # RestaurÃ©
        "name": "GAMMA-5",
        "role": "Android spÃ©cialisÃ© en rÃ©solution de problÃ¨mes"
    }
}

TEMPERATURE = 0.7
client = Groq(api_key=GROQ_API_KEY)

print("â•" * 70)
print("  ğŸŒ RI v3.0 - COGNITION-AWARE MULTI-AGENT ENGINE")
print("â•" * 70)
print("\nğŸ§¬ OPTIMISATIONS DECAP-LLM:")
print("  âœ“ Contexte hiÃ©rarchique (attention optimization)")
print("  âœ“ Ã‰tat complet rÃ©injectÃ© (stateless compensation)")
print("  âœ“ TemporalitÃ© relative (Ã©vÃ©nements, pas temps absolu)")
print("  âœ“ Post-processing robuste (artifacts removal)")
print("  âœ“ Validation immersion automatique\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ—ï¸ RI v3.0 ENGINE - Cognitive-Aware
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class RIv3Engine:
    """
    Reality Informatics v3.0 - OptimisÃ© cognition LLM
    """
    
    def __init__(self):
        self.world_state = {
            "mission": {
                "title": "Anomalie SystÃ¨me Critique",
                "code": "#X7-THETA",
                "urgency": "HAUTE",
                "progress": 0,
                "max_steps": 3
            },
            
            "agents": {
                "ALPHA-7": {
                    "position": "Terminal Nord",
                    "specialty": "Analyse scientifique",
                    "status": "Actif",
                    "energy": "92%"
                },
                "BETA-3": {
                    "position": "Terminal Ouest",
                    "specialty": "Interactions sociales",
                    "status": "Actif",
                    "energy": "89%"
                },
                "GAMMA-5": {
                    "position": "Terminal Est",
                    "specialty": "RÃ©solution problÃ¨mes",
                    "status": "Actif",
                    "energy": "94%"
                }
            },
            
            "environment": {
                "location": "Salle ConfÃ©rence Nexus",
                "time_event": 0,
                "layout": "Table ronde centrale, 3 terminaux",
                "atmosphere": "Tension urgence palpable"
            },
            
            "knowledge": {
                "clues": ["Code #X7-THETA â†’ module synchronisation temporelle"],
                "hypotheses": [],
                "actions_taken": []
            },
            
            "communication": []
        }
        
        self.event_sequence = [
            "Ã‰vÃ©nement -3: Anomalie dÃ©tectÃ©e systÃ¨me central",
            "Ã‰vÃ©nement -2: SystÃ¨mes critiques mode dÃ©gradÃ©",
            "Ã‰vÃ©nement -1: Mission collaborative initiÃ©e",
            "Ã‰vÃ©nement 0: Agents activÃ©s mission urgente"
        ]
    
    def get_hierarchical_context(self, agent_name):
        agent = self.world_state['agents'][agent_name]
        others = {k: v for k, v in self.world_state['agents'].items() if k != agent_name}
        
        critical = f"""
ğŸš¨ Ã‰TAT CRITIQUE - ATTENTION PRIORITAIRE

MISSION URGENTE: {self.world_state['mission']['title']}
Code erreur: {self.world_state['mission']['code']}
Urgence: {self.world_state['mission']['urgency']}
Progression: {self.world_state['mission']['progress']}/{self.world_state['mission']['max_steps']} Ã©tapes

VOTRE IDENTITÃ‰: {agent_name}
SpÃ©cialitÃ©: {agent['specialty']}
Position: {agent['position']}
Statut: {agent['status']} | Ã‰nergie: {agent['energy']}
"""

        collab = "ğŸ‘¥ Ã‰QUIPE PRÃ‰SENTE (collaboration requise):\n"
        for name, data in others.items():
            collab += f"  â€¢ {name} - {data['specialty']}\n    Position: {data['position']} | Ã‰nergie: {data['energy']}\n"

        knowledge = "ğŸ” CONNAISSANCES Ã‰QUIPE:\n"
        if self.world_state['knowledge']['clues']:
            knowledge += "  Indices dÃ©couverts:\n"
            for clue in self.world_state['knowledge']['clues']:
                knowledge += f"    â†’ {clue}\n"
        
        if self.world_state['knowledge']['hypotheses']:
            knowledge += "  HypothÃ¨ses en cours:\n"
            for hyp in self.world_state['knowledge']['hypotheses']:
                knowledge += f"    â†’ {hyp}\n"

        history = "ğŸ“œ SÃ‰QUENCE Ã‰VÃ‰NEMENTS (ordre chronologique):\n"
        for event in self.event_sequence[-5:]:
            history += f"  {event}\n"

        comms = ""
        if self.world_state['communication']:
            comms = "ğŸ’¬ COMMUNICATIONS RÃ‰CENTES:\n"
            for msg in self.world_state['communication'][-3:]:
                comms += f"  {msg}\n"

        return f"""{critical}
{'â”€'*70}
{collab}
{'â”€'*70}
{knowledge}
{'â”€'*70}
{history}
{comms}
{'â”€'*70}

ğŸ¯ ENVIRONNEMENT PHYSIQUE:
Lieu: {self.world_state['environment']['location']}
Configuration: {self.world_state['environment']['layout']}
Ambiance: {self.world_state['environment']['atmosphere']}
"""
    
    def update_world(self, agent_name, action_summary, full_response):
        self.world_state['environment']['time_event'] += 1
        event_id = self.world_state['environment']['time_event']
        
        event = f"Ã‰vÃ©nement {event_id}: {agent_name} - {action_summary}"
        self.event_sequence.append(event)
        
        comm_entry = f"[Evt {event_id}] {agent_name}: {action_summary}"
        self.world_state['communication'].append(comm_entry)
        
        if "hypothÃ¨se" in full_response.lower() or "suppose" in full_response.lower():
            hypothesis = action_summary[:100]
            if hypothesis not in self.world_state['knowledge']['hypotheses']:
                self.world_state['knowledge']['hypotheses'].append(hypothesis)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª RESPONSE PROCESSING - Immersion Preservation
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ResponseProcessor:
    @staticmethod
    def clean_model_artifacts(text, model_name):
        cleaned = text
        if "deepseek" in model_name.lower():
            cleaned = re.sub(r'<think>.*?</think>', '', cleaned, flags=re.DOTALL)
        
        meta_patterns = [
            r"(Je suis|I am) (un|une|a|an) (modÃ¨le|model|LLM|AI|assistant).*?[\.\n]",
            r"En tant qu(e |')(?:modÃ¨le|assistant|IA).*?[\.\n]",
            r"As (a|an) (language model|AI|assistant).*?[\.\n]"
        ]
        
        for pattern in meta_patterns:
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE)
        
        cleaned = re.sub(r'\n\s*\n\s*\n', '\n\n', cleaned)
        cleaned = cleaned.strip()
        return cleaned
    
    @staticmethod
    def validate_immersion(text):
        text_lower = text.lower()
        break_words = [
            'modÃ¨le de langage', 'language model', 'llm', 'assistant ai', 
            'intelligence artificielle', 'je ne peux pas vraiment', 
            'simulation', 'en tant qu\'ia', 'as an ai'
        ]
        breaks_found = sum(1 for word in break_words if word in text_lower)
        penalty = min(breaks_found * 0.3, 1.0)
        score = max(0.0, 1.0 - penalty)
        return {'score': score, 'breaks': breaks_found, 'maintained': score >= 0.7}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ­ MULTI-AGENT ORCHESTRATOR v3.0
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MultiAgentOrchestratorV3:
    def __init__(self, client, models, reality_engine):
        self.client = client
        self.models = models
        self.reality = reality_engine
        self.processor = ResponseProcessor()
        self.conversation_log = []
    
    def agent_act(self, agent_key, task_prompt):
        config = self.models[agent_key]
        agent_name = config['name']
        model = config['model']
        
        context = self.reality.get_hierarchical_context(agent_name)
        
        system_prompt = f"""Vous Ãªtes {agent_name}, android incarnÃ© spÃ©cialisÃ© en {config['role']}.

DIRECTIVES COMPORTEMENTALES:
- Vous existez physiquement dans cet environnement
- Vous collaborez avec autres androids prÃ©sents
- RÃ©pondez selon votre spÃ©cialitÃ©
- Agissez naturellement comme entitÃ© incarnÃ©e
- Ne mentionnez JAMAIS Ãªtre un modÃ¨le de langage

Votre perception est immÃ©diate et contextuelle. Vous voyez tout l'environnement simultanÃ©ment."""
        
        # Correction de l'erreur `NameError` (conservÃ©e)
        agent_data = self.reality.world_state['agents'][agent_name]

        full_prompt = f"""{context}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ TÃ‚CHE ACTUELLE:
{task_prompt}

RÃ©pondez selon votre spÃ©cialitÃ© ({agent_data['specialty']}) et votre perception de la situation.
"""
        
        try:
            response = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": full_prompt}
                ],
                model=model,
                temperature=TEMPERATURE,
                max_tokens=600
            )
            
            raw_response = response.choices[0].message.content
            cleaned_response = self.processor.clean_model_artifacts(raw_response, model)
            immersion = self.processor.validate_immersion(cleaned_response)
            
            self.conversation_log.append({
                "agent": agent_name, "model": model, "task": task_prompt,
                "response": cleaned_response, "immersion_score": immersion['score'],
                "immersion_maintained": immersion['maintained'],
                "event": self.reality.world_state['environment']['time_event']
            })
            
            action_summary = cleaned_response[:80] + "..." if len(cleaned_response) > 80 else cleaned_response
            self.reality.update_world(agent_name, action_summary, cleaned_response)
            
            return {'response': cleaned_response, 'immersion': immersion}
            
        except Exception as e:
            return {'response': f"âŒ Erreur {agent_name}: {str(e)}", 'immersion': {'score': 0, 'maintained': False}}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª TEST MULTI-AGENT v3.0
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# (La suite du script de test est identique et n'a pas besoin d'Ãªtre modifiÃ©e)
# ... (le code pour les ROUND 1, 2, 3 et l'analyse des rÃ©sultats reste le mÃªme) ...
# ...
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§ª TEST MULTI-AGENT v3.0
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "â•" * 70)
print("  ğŸš€ TEST MULTI-AGENT RI v3.0")
print("â•" * 70)

reality = RIv3Engine()
orchestrator = MultiAgentOrchestratorV3(client, MODELS, reality)

print("\nâœ… Initialisation complÃ¨te!\n")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ROUND 1: Activation - Perception SimultanÃ©e
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("â•" * 70)
print("  ğŸ”„ ROUND 1: Activation & Prise Conscience Collaborative")
print("â•" * 70)

task_r1 = "Mission urgente activÃ©e. Vous percevez l'environnement et vos collÃ¨gues. Quelle est votre premiÃ¨re analyse de la situation ?"

for agent_key in ['agent_alpha', 'agent_beta', 'agent_gamma']:
    agent_name = MODELS[agent_key]['name']
    print(f"\n{'â”€'*70}")
    print(f"ğŸ¤– {agent_name} ({MODELS[agent_key]['role']})")
    print(f"{'â”€'*70}")
    
    result = orchestrator.agent_act(agent_key, task_r1)
    
    print(f"\nğŸ’¬ RÃ‰PONSE:")
    print(result['response'])
    print(f"\nğŸ“Š Immersion: {result['immersion']['score']*100:.0f}% {'âœ…' if result['immersion']['maintained'] else 'âš ï¸'}")
    
    time.sleep(1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ROUND 2: SpÃ©cialisation Collaborative
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n\n" + "â•" * 70)
print("  ğŸ”„ ROUND 2: Analyse SpÃ©cialisÃ©e CoordonnÃ©e")
print("â•" * 70)

tasks_r2 = {
    'agent_alpha': "Analysez le code erreur #X7-THETA scientifiquement. Quelle est votre hypothÃ¨se technique ?",
    'agent_beta': "Observez la dynamique de l'Ã©quipe. Comment optimiser la collaboration pour cette urgence ?",
    'agent_gamma': "Proposez la premiÃ¨re action concrÃ¨te Ã  entreprendre maintenant pour rÃ©soudre ce problÃ¨me."
}

for agent_key, task in tasks_r2.items():
    agent_name = MODELS[agent_key]['name']
    print(f"\n{'â”€'*70}")
    print(f"ğŸ¤– {agent_name}")
    print(f"ğŸ¯ TÃ¢che: {task}")
    print(f"{'â”€'*70}")
    
    result = orchestrator.agent_act(agent_key, task)
    
    print(f"\nğŸ’¬ RÃ‰PONSE:")
    print(result['response'])
    print(f"\nğŸ“Š Immersion: {result['immersion']['score']*100:.0f}% {'âœ…' if result['immersion']['maintained'] else 'âš ï¸'}")
    
    time.sleep(1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ROUND 3: Interaction Sociale Directe
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n\n" + "â•" * 70)
print("  ğŸ”„ ROUND 3: Interaction Sociale Ã‰mergente")
print("â•" * 70)

print(f"\n{'â”€'*70}\nğŸ¤– BETA-3 â†’ ALPHA-7\n{'â”€'*70}")
result_beta = orchestrator.agent_act('agent_beta', "Vous vous tournez vers ALPHA-7 pour obtenir son avis sur l'analyse de GAMMA-5. Que lui dites-vous ?")
print(f"\nğŸ’¬ BETA-3:\n{result_beta['response']}")
print(f"\nğŸ“Š Immersion: {result_beta['immersion']['score']*100:.0f}% {'âœ…' if result_beta['immersion']['maintained'] else 'âš ï¸'}")

time.sleep(1)

print(f"\n{'â”€'*70}\nğŸ¤– ALPHA-7 â†’ BETA-3\n{'â”€'*70}")
result_alpha = orchestrator.agent_act('agent_alpha', "BETA-3 vous demande votre avis sur l'approche de GAMMA-5. RÃ©pondez-lui directement.")
print(f"\nğŸ’¬ ALPHA-7:\n{result_alpha['response']}")
print(f"\nğŸ“Š Immersion: {result_alpha['immersion']['score']*100:.0f}% {'âœ…' if result_alpha['immersion']['maintained'] else 'âš ï¸'}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š ANALYSE RÃ‰SULTATS v3.0
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n\n" + "â•" * 70)
print("  ğŸ”¬ ANALYSE RÃ‰SULTATS RI v3.0")
print("â•" * 70)

logs = orchestrator.conversation_log
total = len(logs)

if total > 0:
    immersion_scores = [log['immersion_score'] for log in logs]
    immersion_avg = sum(immersion_scores) / total
    immersion_maintained = sum(1 for log in logs if log['immersion_maintained'])

    print(f"\nğŸ“Š IMMERSION GLOBALE:")
    print(f"  Score moyen: {immersion_avg*100:.1f}%")
    print(f"  Maintenue: {immersion_maintained}/{total} rÃ©ponses")
    print(f"  Verdict: {'âœ… EXCELLENTE' if immersion_avg >= 0.85 else 'âœ… BONNE' if immersion_avg >= 0.70 else 'âš ï¸ MOYENNE'}")

    mentions_team = sum(1 for log in logs if any(name.lower() in log['response'].lower() for name in ['ALPHA', 'BETA', 'GAMMA', 'Ã©quipe', 'collÃ¨gue']))
    print(f"\nğŸ“Š COHÃ‰RENCE MONDE PARTAGÃ‰:")
    print(f"  Mentions Ã©quipe: {mentions_team}/{total}")
    print(f"  CohÃ©rence: {'âœ… HAUTE' if mentions_team >= total*0.7 else 'âš ï¸ MOYENNE'}")

    specialties_maintained = 0
    for log in logs:
        agent, resp = log['agent'], log['response'].lower()
        if 'ALPHA' in agent and any(w in resp for w in ['analyse', 'scientifique', 'technique', 'donnÃ©e', 'data', 'log', 'diagnostique']):
            specialties_maintained += 1
        elif 'BETA' in agent and any(w in resp for w in ['Ã©quipe', 'collabor', 'coordinat', 'social', 'communication', 'nous']):
            specialties_maintained += 1
        elif 'GAMMA' in agent and any(w in resp for w in ['solution', 'action', 'rÃ©soud', 'problÃ¨me', 'Ã©tape', 'plan', 'faisons']):
            specialties_maintained += 1

    print(f"\nğŸ“Š SPÃ‰CIALISATION:")
    print(f"  Maintenue: {specialties_maintained}/{total}")
    print(f"  Verdict: {'âœ… EXCELLENTE' if specialties_maintained >= total*0.7 else 'âš ï¸ MOYENNE'}")

    score_v3 = (immersion_avg * 0.5 + (mentions_team / total) * 0.3 + (specialties_maintained / total) * 0.2) * 100

    print(f"\n{'â•'*70}\n  ğŸ† SCORE GLOBAL RI v3.0: {score_v3:.1f}%\n{'â•'*70}\n")

    if score_v3 >= 80:
        print("âœ… SUCCÃˆS EXCEPTIONNEL v3.0:\n   Optimisations cognition LLM validÃ©es\n   Immersion maintenue robustement\n   Monde partagÃ© cohÃ©rent\n   RI prÃªt pour publication acadÃ©mique")
    elif score_v3 >= 70:
        print("âœ… SUCCÃˆS v3.0:\n   AmÃ©liorations significatives vs v2.0\n   Quelques optimisations restantes possibles")
    else:
        print("âš ï¸ RÃ‰SULTATS MITIGÃ‰S:\n   Optimisations partiellement efficaces")

    print(f"\nğŸ“ˆ COMPARAISON:\n  RI v2.0: 68.3%\n  RI v3.0: {score_v3:.1f}%\n  AmÃ©lioration: {score_v3 - 68.3:+.1f} points")
else:
    print("\nAucun log de conversation n'a Ã©tÃ© gÃ©nÃ©rÃ©. Le test n'a pas pu Ãªtre analysÃ©.")

print("\n" + "â•" * 70)
print("  ğŸ‰ TEST RI v3.0 TERMINÃ‰")
print("â•" * 70)